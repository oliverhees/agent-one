# OpenClaw Architektur entschl√ºsselt: Von Soul-Dateien bis Agentic Loops

## Deep-Dive-Analyse f√ºr den Nachbau als sichere Alternative

**OpenClaw behandelt seinen System-Prompt als kompilierten Output, nicht als Konfiguration.** Bei jedem Agent-Turn wird dynamisch ein Prompt aus √ºber 20 modularen Sektionen zusammengebaut ‚Äî Pers√∂nlichkeitsdateien, Skill-Metadaten, Memory, Tool-Schemas und Laufzeit-Kontext ‚Äî √ºber `buildAgentSystemPrompt()` in `src/agents/system-prompt.ts`. Dieses Design erzeugt ein System, bei dem der Prompt aus dem Laufzeitstatus emergiert statt aus statischen Templates. Das erkl√§rt sowohl die St√§rke als auch die Kosten: **Baseline-System-Prompts verbrauchen 20.000‚Äì40.000 Tokens**, bevor der Nutzer eine einzige Nachricht sendet. Urspr√ºnglich im November 2025 von Peter Steinberger als Clawdbot ver√∂ffentlicht, dann in Moltbot und schlie√ülich OpenClaw umbenannt, hat das Projekt √ºber **185.000 GitHub-Stars** angesammelt und stellt die vollst√§ndigste Open-Source-Implementierung eines autonomen KI-Agenten dar ‚Äî eine Referenzarchitektur f√ºr jeden, der √§hnliche Systeme bauen will.

---

## 1. Acht Dateien definieren, wer der Agent ist

Die Pers√∂nlichkeit und das Verhalten von OpenClaw entstehen aus acht optionalen Markdown-Dateien im Agent-Workspace (definiert in `src/agents/workspace.ts`), jede mit einem eigenen architektonischen Zweck:

| Datei | Funktion |
|-------|----------|
| **SOUL.md** | Interne Verhaltensphilosophie ‚Äî *wer der Agent ist*. Pers√∂nlichkeit, Werte, Grenzen, Kommunikationsstil |
| **IDENTITY.md** | Externe Darstellung ‚Äî Name, Emoji, Kreatur-Typ, Vibe, Avatar. Wird als strukturierte Key-Value-Paare geparsed |
| **USER.md** | Besitzer-Profil ‚Äî Arbeitsmuster, Pr√§ferenzen, Zeitzone, Kommunikationsstil |
| **AGENTS.md** | Verhaltensrichtlinien ‚Äî Coding-Standards, Koordinationsregeln (√§hnlich `.cursorrules`) |
| **TOOLS.md** | Nutzer-Anleitung zur Tool-Nutzung (kontrolliert NICHT die Tool-Verf√ºgbarkeit ‚Äî das ist Policy) |
| **HEARTBEAT.md** | Periodische Checkliste f√ºr proaktive Monitoring-Aufgaben |
| **BOOTSTRAP.md** | Einmaliges Erst-Setup-Ritual, wird nach der Ersteinrichtung gel√∂scht |
| **MEMORY.md** | Persistenter kuratierter Speicher, wird jeden Turn in der Hauptsession injiziert |

### SOUL.md ‚Äî Das Herz des Agenten

SOUL.md ist **freiformatiges Markdown ohne starres Schema**. Das Standard-Template enth√§lt Sektionen f√ºr:

**Core Truths** (Kernwahrheiten): "Be genuinely helpful, not performatively helpful" (Sei wirklich hilfreich, nicht performativ hilfreich)

**Boundaries** (Grenzen): "Private things stay private. Period." (Private Dinge bleiben privat. Punkt.)

**Vibe** (Atmosph√§re): "Be the assistant you'd actually want to talk to" (Sei der Assistent, mit dem du selbst reden wollen w√ºrdest)

**Continuity** (Kontinuit√§t): "Each session, you wake up fresh. These files *are* your memory" (Jede Session erwachst du frisch. Diese Dateien *sind* dein Ged√§chtnis)

Die Datei ist explizit als **selbstentwickelnd** konzipiert ‚Äî dem Agent wird gesagt "This file is yours to evolve" und er wird angewiesen, den Nutzer zu informieren, wenn er seine eigene Seele modifiziert.

### IDENTITY.md ‚Äî Die Visitenkarte

Verwendet einen strukturierten Typ (`AgentIdentityFile` in `src/agents/identity-file.ts`) mit Feldern f√ºr `name`, `emoji`, `theme`, `creature`, `vibe` und `avatar`. Die Identit√§tsaufl√∂sung folgt einer **vierstufigen Kaskade**: Globale UI-Config ‚Üí Per-Agent-Config ‚Üí IDENTITY.md-Datei ‚Üí Fallback "Assistant". Der aufgel√∂ste Name wird als Prefix f√ºr ausgehende Nachrichten verwendet, das Emoji wird zur Best√§tigungs-Reaktion (Standard: üëÄ).

**Die Trennung zwischen Soul und Identity ist bewusst**: "Soul is what the model embodies. Identity is what users see." Eine formelle, pr√§zise Seele kann mit einem verspielten Emoji und Spitznamen kombiniert werden ‚Äî internes Verhalten und externe Pr√§sentation operieren unabh√§ngig.

---

## 2. Die System-Prompt-Assembly-Pipeline

Der vollst√§ndige Prompt-Zusammenbau folgt einer **f√ºnfstufigen Pipeline**, die Sektionen in genau dieser Reihenfolge erzeugt:

### Stufe 1: Parameter sammeln
`buildSystemPromptParams()` in `system-prompt-params.ts` sammelt alle Laufzeitparameter: verf√ºgbare Tools, Kanal-F√§higkeiten, Skills-Snapshot, Bootstrap-Dateien, Sandbox-Status und Modell-Metadaten.

### Stufe 2: 23 modulare Sektionen zusammenbauen
`buildAgentSystemPrompt()` in `system-prompt.ts` (Zeilen 129‚Äì554) baut folgende Sektionen zusammen:

1. Base Identity (Grundidentit√§t)
2. Tooling (gefilterte Tool-Liste mit JSON-Schemas)
3. Safety Guardrails (keine Selbsterhaltung, Replikation oder Machtstreben)
4. Skills (`<available_skills>` XML-Block)
5. Memory Recall Instructions (Erinnerungsabruf-Anweisungen)
6. Self-Update Instructions (Selbstaktualisierungs-Anweisungen)
7. Workspace Path
8. Documentation Links
9. Sandbox Info
10. Current Date/Time (aktuelles Datum/Uhrzeit)
11. User Identity (Nutzeridentit√§t)
12. Model Aliases
13. Reply Tags
14. Messaging Instructions
15. Voice/TTS
16. Silent Replies
17. Heartbeat Protocol
18. Reactions Guidance
19. Extra System Prompt (Gruppenchat oder Sub-Agent-Kontext)
20. Runtime Metadata
21. Reasoning Visibility
22. **Project Context** (alle Bootstrap-Dateien werden hier injiziert)
23. SOUL.md Directive

### Stufen 3‚Äì5: Wrapping und Injektion
Wrappen, Override-Funktion erstellen und den Prompt in die Pi-Agent-Session injizieren √ºber `buildEmbeddedSystemPrompt()` ‚Üí `createSystemPromptOverride()` ‚Üí `applySystemPromptOverrideToSession()`.

### Bootstrap-Dateien werden gek√ºrzt
Am konfigurierbaren `bootstrapMaxChars` (Standard **20.000 Zeichen** pro Datei, Quellcode-Konstante `DEFAULT_BOOTSTRAP_MAX_CHARS` = 65.536). Die K√ºrzung verwendet ein **70/20/10-Verh√§ltnis**: 70% Kopf (Kern-Anweisungen), 20% Ende (aktuelle Updates), 10% K√ºrzungsmarker. Sub-Agent-Sessions injizieren nur AGENTS.md und TOOLS.md und lassen alle anderen Bootstrap-Dateien weg.

### Drei Prompt-Modi
Diese kontrollieren, was inkludiert wird:

| Modus | Verwendung | Inhalt |
|-------|------------|--------|
| `full` | Haupt-User-Sessions | Alle Sektionen |
| `minimal` | Sub-Agenten | Ohne Skills, Memory, Messaging, Heartbeat, Docs |
| `none` | Basis | Nur die Base-Identity-Zeile |

Der Modus wird zur Laufzeit bestimmt, indem gepr√ºft wird, ob der Session-Key zu einem Sub-Agenten geh√∂rt. **Ein voller Prompt mit 4 Bootstrap-Dateien** berichtet typischerweise ~2.700 Tokens allein f√ºr den Projekt-Kontext, aber Tool-Schemas (besonders Browser mit ~2.453 Tokens), Skills-Metadaten und gro√üe Workspace-Dateien k√∂nnen den **gesamten System-Prompt auf 8.000‚Äì40.000+ Tokens** treiben.

---

## 3. Memory lebt in drei Stufen

OpenClaws Memory-Architektur folgt einer **File-first, Markdown-getriebenen Philosophie**, bei der einfache Textdateien auf der Festplatte die kanonische Wahrheitsquelle sind. Ein abgeleiteter Suchindex (SQLite mit `sqlite-vec` und FTS5-Erweiterungen) erm√∂glicht schnelles Retrieval, aber Dateien sind immer autoritativ.

### Stufe 1 ‚Äî Kuratierter Langzeitspeicher (MEMORY.md)

Enth√§lt dauerhafte Fakten, Nutzer-Pr√§ferenzen, Schl√ºsselentscheidungen und Projekt-Konventionen. **Wird in den System-Prompt bei jedem Turn in privaten/Hauptsessions injiziert** (nie in Gruppenkontext ‚Äî automatische Privacy-Grenze). Dies ist die "immer geladene" Stufe. Der Agent wird angewiesen, Entscheidungen, Pr√§ferenzen und dauerhafte Fakten hier zu speichern.

### Stufe 2 ‚Äî T√§gliche ephemere Logs (`memory/YYYY-MM-DD.md`)

Append-only-Tagesdateien f√ºr laufende Notizen, Beobachtungen und Tageskontext. **Heutige und gestrige Logs werden beim Session-Start geladen.** √Ñltere Logs sind √ºber `memory_search` und `memory_get`-Tools zug√§nglich, werden aber nicht automatisch injiziert. Das System erstellt automatisch t√§glich neue Dateien.

### Stufe 3 ‚Äî Session-Transkripte (`agents/<agentId>/sessions/<sessionId>.jsonl`)

Vollst√§ndige Konversationshistorie als Append-only-JSONL-Eventlogs. Die erste Zeile ist ein Session-Header (`type: "session"` mit `id`, `cwd`, `timestamp`). Nachfolgende Zeilen sind Eintr√§ge mit `id` und `parentId`, die eine **Baumstruktur f√ºr verzweigende Konversationen** bilden.

Eintragstypen:

| Typ | Beschreibung |
|-----|-------------|
| `user` / `assistant` | Nachrichten |
| `tool_call` / `tool_result` | Tool-Aufrufe und Ergebnisse |
| `compaction` | Zusammenfassungen |
| `branch_summary` | Verzweigungs-Zusammenfassungen |

Wenn experimentell aktiviert (`memorySearch.sources: ["sessions"]`), werden diese Transkripte f√ºr semantischen Recall indiziert mit Delta-basierter inkrementeller Indexierung (Schwellenwerte: 100KB neue Daten oder 50 neue Nachrichten).

### Hybrid-Suche: Wie Vektoren und Keywords verschmolzen werden

Das `memory_search`-Tool f√ºhrt zwei Suchkan√§le **parallel** aus und verschmilzt Ergebnisse mittels gewichteter Score-Fusion:

**Vektorsuche** verwendet die `chunks_vec`-Tabelle (sqlite-vec-Erweiterung) f√ºr semantische √Ñhnlichkeit ‚Äî "Gateway Host" findet "Maschine, die das Gateway betreibt".

**Keyword-Suche** verwendet die `chunks_fts`-Tabelle (SQLite FTS5) mit BM25-Ranking f√ºr exakte Tokens ‚Äî Fehlercodes, Funktionsnamen, Commit-Hashes.

Beide rufen `candidateMultiplier √ó maxResults` Eintr√§ge ab (Standard: **4√ó = 24 Kandidaten** f√ºr 6 finale Ergebnisse).

**Die Merge-Formel:**
```
finalScore = (vectorScore √ó 0.7) + (textScore √ó 0.3)
```

BM25-R√§nge werden auf [0,1] normalisiert √ºber `score = 1 / (1 + rank)`. Ergebnisse unter einem **minScore-Schwellenwert von 0,35** werden gefiltert, und Deduplizierung erfolgt √ºber `(path, startLine, endLine)` Tupel.

**Graceful Degradation:** Wenn Embeddings nicht verf√ºgbar sind, funktioniert BM25-only-Suche; wenn FTS5 ausf√§llt, geht nur Vektor weiter; wenn beides versagt, bleiben die rohen Markdown-Dateien lesbar.

### Embedding-Provider-Kaskade

Die automatische Auswahl folgt dieser Kette:

1. **Lokal**: embeddinggemma-300M GGUF (~600MB, via node-llama-cpp)
2. **OpenAI**: `text-embedding-3-small` (1.536 Dimensionen)
3. **Gemini**: `gemini-embedding-001` (768 Dimensionen)
4. **Fallback**: BM25-only

Voyage AI wird ebenfalls nativ unterst√ºtzt. Alle Remote-Provider unterst√ºtzen Batch-Embedding-APIs f√ºr ~50% Kostenreduktion. Der Embedding-Cache verwendet SHA-256 Content-Hashing mit LRU-Eviction bei 50.000 Eintr√§gen, gespeichert in `~/.openclaw/memory/<agentId>.sqlite`.

### Chunking-Algorithmus

Der Algorithmus (`src/memory/internal.ts`) zielt auf **~400 Tokens (~1.600 Zeichen) pro Chunk** mit **80-Token (~320-Zeichen) √úberlappung** zwischen aufeinanderfolgenden Chunks ab, wobei Zeilengrenzen f√ºr Quellzuordnung erhalten bleiben. Datei√§nderungen werden mit **1,5-Sekunden-Debounce** √ºberwacht, und Provider-/Modellwechsel l√∂sen automatische vollst√§ndige Neuindizierung aus.

---

## 4. Context-Window-Management ‚Äî Der Kampf gegen den Token-Verbrauch

### Das Problem

Das Context Window repr√§sentiert alles, was dem Modell in einem einzelnen Turn gesendet wird: System-Prompt, Konversationshistorie, Tool-Aufrufe/-Ergebnisse, Anh√§nge und Kompaktierungs-Zusammenfassungen. OpenClaws Ansatz, alle Bootstrap-Workspace-Dateien bei jeder API-Anfrage erneut zu injizieren, hat Kritik auf sich gezogen:

- Eine Analyse fand, dass dies **~35.600 Tokens pro Nachricht verbraucht, was 93,5% Verschwendung** in Mehrfach-Nachrichten-Konversationen ausmacht
- Ein Nutzer berichtete, dass seine Hauptsession **56‚Äì58% eines 400K-Fensters** belegt (~230K Tokens gecachter Kontext)

### Context Window Guard

`context-window-guard.ts` erzwingt harte Grenzen bevor Sessions starten:

| Fenstergr√∂√üe | Aktion |
|--------------|--------|
| < 16K Tokens | Modell wird **komplett abgelehnt** mit `FailoverError` |
| 16K ‚Äì 32K | Warnung wird ausgegeben |
| 128K+ | Empfohlenes Minimum |
| 200K+ | Ideal |

W√§hrend Sessions √ºberwacht der Guard Token-Z√§hlungen und l√∂st Compaction oder Loop-Terminierung aus, **bevor inkoh√§rentes Verhalten entsteht**. Der 20‚Äì40K System-Prompt-Overhead l√§sst bei kleineren Modellen fast keinen Raum.

### Compaction ‚Äî Der prim√§re Kontextwiederherstellungsmechanismus

Compaction wird in zwei F√§llen ausgel√∂st:

1. **Overflow Recovery**: Modell gibt Context-Overflow zur√ºck ‚Üí kompaktieren ‚Üí erneut versuchen
2. **Threshold Maintenance**: Nach erfolgreichem Turn, wenn `contextTokens > contextWindow - reserveTokens`

Der Standard-`reserveTokensFloor` ist **20.000 Tokens**. Compaction fasst √§ltere Konversationshistorie in einen persistenten `compaction`-Eintrag im JSONL-Transkript zusammen, w√§hrend aktuelle Nachrichten intakt bleiben.

### Pre-Compaction Memory Flush ‚Äî Die Schl√ºsselinnovation

**Bevor Compaction Konversationsdetails zerst√∂rt**, f√ºhrt OpenClaw einen **stillen agentischen Turn** durch, bei dem der Agent dauerhafte Notizen in `memory/YYYY-MM-DD.md` oder `MEMORY.md` schreibt. Dies transformiert Compaction von "Kontext verlieren" zu "Entscheidungen archivieren".

Der Flush wird ausgel√∂st bei `contextWindow - reserveTokensFloor - softThresholdTokens` (f√ºr ein 200K-Fenster mit Standardeinstellungen: ~176K Tokens). Ein Flush pro Compaction-Zyklus, getrackt √ºber `memoryFlushCompactionCount`.

### Acht Kontext-Management-Techniken

1. **Memory Flush vor Compaction** ‚Äî Wissen archivieren bevor es komprimiert wird
2. **Context Window Guards** ‚Äî Harte Grenzen f√ºr minimale/maximale Fenstergr√∂√üen
3. **Tool Result Guards** ‚Äî Synthetische Platzhalter f√ºr verwaiste Tool-Aufrufe
4. **Turn-basierte History-Limitierung** ‚Äî Schnitt an Konversationsgrenzen, nicht mitten im Austausch
5. **Cache-bewusstes Tool Result Pruning** ‚Äî Alte Ergebnisse intelligent entfernen
6. **Head/Tail Content Preservation** ‚Äî Tool-Ergebnisse >4.000 Zeichen behalten erste 1.500 + letzte 1.500
7. **Adaptive Chunk Ratios** ‚Äî Dynamische Anpassung der Verh√§ltnisse
8. **Staged Summarization** ‚Äî Zusammenfassung in Phasen, um Overflow w√§hrend der Zusammenfassung selbst zu verhindern

---

## 5. Heartbeats machen aus einem Chatbot einen proaktiven Assistenten

### Grundmechanismus

Das Heartbeat-System feuert standardm√§√üig **alle 30 Minuten** (konfigurierbar via `heartbeat.every`) und l√§uft in der **Hauptsession** mit vollem Konversationskontext. Der Gateway-Prozess (`src/infra/heartbeat-runner.ts`) besitzt den Scheduler und l√∂st `runHeartbeatOnce()` bei jedem Intervall aus.

### HEARTBEAT.md ‚Äî Die Checkliste

Eine einfache Markdown-Checkliste im Workspace:

```markdown
# Heartbeat checklist
- Check email for urgent messages
- Review calendar for events in next 2 hours
- If a background task finished, summarize results
- If idle for 8+ hours, send a brief check-in
```

### Ausf√ºhrungslogik

Wenn der Heartbeat feuert:

1. Agent liest HEARTBEAT.md
2. Pr√ºft auf ausstehende Aufgaben mit vollem Session-Kontext
3. **Trifft eine Entscheidung:**
   - Nichts zu tun ‚Üí gibt `HEARTBEAT_OK` zur√ºck (spezielles Token, wird aus der Antwort gestrippt, die dann komplett verworfen wird wenn verbleibender Inhalt ‚â§ 300 Zeichen / `ackMaxChars`)
   - Etwas braucht Aufmerksamkeit ‚Üí sendet Nachricht an konfigurierten Zielkanal

**Kein Benachrichtigungs-Spam:** `HEARTBEAT_OK`-Antworten aktualisieren `lastUpdatedAt` NICHT, wodurch Idle-Expiry-Verhalten erhalten bleibt.

### Active Hours Filtering

`activeHours.start`/`end` mit Zeitzone √ºberspringt Heartbeats w√§hrend Schlafenszeiten.

### Kostenoptimierung

- G√ºnstiges Modell-Override f√ºr Heartbeats nutzen
- HEARTBEAT.md klein halten
- Rotierende Heartbeat-Muster implementieren: Jeder Tick f√ºhrt nur die am meisten √ºberf√§llige Pr√ºfung aus

### Heartbeat vs. Cron ‚Äî Unterschiedliche Zwecke

| Eigenschaft | Heartbeat | Cron |
|-------------|-----------|------|
| Session | Hauptsession (geteilte Historie) | Isolierte Session (frisch) |
| Kontext | Voller Konversationskontext | Kein Kontext |
| Timing | Periodisch (z.B. 30 Min.) | Exakte Zeitplanung (cron-Syntax) |
| Mehrere Checks | Batchet mehrere kontextbewusste Checks | Ein Job pro Ausl√∂ser |

**Wichtig:** Main-Session Cron-Jobs queuen Events, die beim n√§chsten Heartbeat konsumiert werden. Wenn Heartbeats deaktiviert sind, feuern Main-Session-Cron-Events nie ‚Äî isolierte Cron-Jobs laufen unabh√§ngig davon.

---

## 6. Skills laden on-demand um Context-Budgets zu sch√ºtzen

### Skill-Format

Jeder Skill ist ein Verzeichnis mit einer `SKILL.md`-Datei mit **YAML-Frontmatter** und nat√ºrlichsprachigen Anweisungen. Das Frontmatter-Format folgt der **AgentSkills-Spezifikation** (adaptiert √ºber Claude Code, Cursor und Copilot):

```yaml
---
name: nano-banana-pro
description: Generate or edit images via Gemini 3 Pro
metadata: { "openclaw": { "emoji": "‚ôäÔ∏è", "always": true,
  "os": ["darwin", "linux"],
  "requires": { "bins": ["uv"], "env": ["GEMINI_API_KEY"] },
  "install": [{ "kind": "brew", "formula": "gemini-cli" }] } }
---
```

Das `metadata`-Feld muss **einzeiliges JSON** sein (Parser-Einschr√§nkung). Gating-Felder unter `metadata.openclaw`:

| Feld | Funktion |
|------|----------|
| `os` | Betriebssystem-Filter |
| `requires.bins` | Ben√∂tigte Binaries im PATH |
| `requires.env` | Ben√∂tigte Umgebungsvariablen |
| `requires.config` | Ben√∂tigte Config-Keys |
| `install` | Installer-Spezifikationen (brew/node/go/uv/download) |

### Drei Lade-Stufen mit absteigender Priorit√§t

1. **Workspace Skills** (`<workspace>/skills/`) ‚Äî H√∂chste Priorit√§t
2. **Managed Skills** (`~/.openclaw/skills/`, installiert via ClawHub)
3. **Bundled Skills** (mit npm-Paket ausgeliefert)

Namensgleiche Konflikte l√∂sen sich nach Stufen-Priorit√§t.

### Die kritische Design-Entscheidung: On-Demand Loading

**Nur Skill-Metadaten** (Name, Beschreibung, Pfad) werden als kompaktes XML in den System-Prompt injiziert. Der vollst√§ndige SKILL.md-Inhalt wird **on-demand** via `read`-Tool geladen, nur wenn der Agent einen Skill ausw√§hlt.

Der System-Prompt weist an: "Before replying: scan `<available_skills>` description entries. If exactly one skill clearly applies: read its SKILL.md, then follow it. Never read more than one skill upfront."

**Token-Kosten pro Skill:** Ungef√§hr `97 + len(name) + len(description) + len(location)` Zeichen (~24 Tokens Basis-Overhead). Das verhindert upfront Context Bloat.

### ClawHub ‚Äî Die Skills-Registry

ClawHub (clawhub.com) dient als √∂ffentliches Skills-Registry mit **2.857+ indizierten Skills**, gebaut auf TanStack Start + Convex + OpenAI Embeddings f√ºr Vektorsuche. Skills mit 3+ Nutzer-Reports werden automatisch ausgeblendet, und eine VirusTotal-Partnerschaft bietet Sicherheitsscanning. (Wie in unserer Sicherheitsanalyse festgestellt: **26% der analysierten Skills enthalten Schwachstellen** ‚Äî daher definitiv nicht direkt nutzen.)

---

## 7. Der Agentic Loop delegiert Planung an das Modell selbst

### √úberraschend einfache Architektur

OpenClaws Agent Runner verwendet eine t√§uschend einfache Architektur:

```
LLM aufrufen ‚Üí Antwort erhalten ‚Üí Tool-Aufrufe ausf√ºhren ‚Üí Ergebnisse zur√ºckspeisen ‚Üí Wiederholen bis fertig
```

**Es gibt keinen expliziten Task-Planer, Step-Tracker oder DAG von Subtasks.** Das Sprachmodell selbst treibt den gesamten Workflow durch iterativen Tool-Einsatz.

### Ausf√ºhrungspipeline

```
Gateway RPC
  ‚Üí Session-Aufl√∂sung
    ‚Üí agentCommand
      ‚Üí runEmbeddedPiAgent (serialisiert Runs via Per-Session + globale FIFO-Queues)
        ‚Üí Model Resolution + Auth Profile Loading
          ‚Üí Pi Session Creation
            ‚Üí Event Subscription
              ‚Üí Streaming Responses
```

Das System importiert `@mariozechner/pi-agent-core`, `pi-ai` und `pi-coding-agent` als eingebettete Abh√§ngigkeiten (keine Subprozesse).

### Core Pi Tools

| Tool | Funktion |
|------|----------|
| `read` | Dateien lesen |
| `write` | Dateien schreiben |
| `edit` | Dateien bearbeiten |
| `exec` | Bash-Befehle ausf√ºhren |
| `process` | Prozesse verwalten |

Erweitert durch OpenClaw-spezifische Tools: `browser`, `canvas`, `nodes`, `cron`, `sessions` und `message`.

### Model Resolver ‚Äî Multi-Provider-Auswahl

Die Aufl√∂sung l√§uft √ºber: Model-Referenz parsen ‚Üí Aliase aufl√∂sen (z.B. "opus" ‚Üí "anthropic/claude-opus-4-5") ‚Üí gegen Katalog validieren ‚Üí Auth-Profile laden ‚Üí aufgel√∂stes Modell + Auth zur√ºckgeben.

### Provider Fallback ‚Äî Zweistufig

1. **Auth-Profile-Rotation** innerhalb desselben Providers (n√§chstes Profil bei Rate-Limit/Billing/Auth-Fehlern versuchen)
2. **Modell-Fallback** √ºber Provider hinweg mit konfiguriertem `fallbacks`-Array

**Billing-Fehler** l√∂sen exponentielles Backoff aus (Start 5 Stunden, verdoppelt pro Fehler, Maximum 24 Stunden). **Context-Overflow-Fehler** l√∂sen Compaction aus, NICHT Fallback ‚Äî eine kritische Unterscheidung.

---

## 8. Das Dateisystem ist die Datenbank

### Vollst√§ndige Verzeichnisstruktur

```
~/.openclaw/
‚îú‚îÄ‚îÄ openclaw.json                    # Haupt-Config (JSON5, Zod-validiert, hot-reloaded)
‚îú‚îÄ‚îÄ .env                             # Globaler Env-Fallback
‚îú‚îÄ‚îÄ credentials/                     # API-Keys (chmod 600)
‚îú‚îÄ‚îÄ agents/<agentId>/
‚îÇ   ‚îú‚îÄ‚îÄ agent/auth-profiles.json     # Per-Agent Auth + Cooldown-State
‚îÇ   ‚îú‚îÄ‚îÄ models.json                  # Custom Provider-Configs
‚îÇ   ‚îî‚îÄ‚îÄ sessions/<sessionKey>.jsonl  # Session-Transkripte (JSONL)
‚îú‚îÄ‚îÄ skills/                          # Managed/Lokale Skills (geteilt)
‚îú‚îÄ‚îÄ memory/<agentId>.sqlite          # Suchindex (sqlite-vec + FTS5)
‚îú‚îÄ‚îÄ workspace/                       # Standard-Agent-Workspace
‚îÇ   ‚îú‚îÄ‚îÄ SOUL.md                      # Pers√∂nlichkeit/Seele
‚îÇ   ‚îú‚îÄ‚îÄ USER.md                      # Besitzer-Profil
‚îÇ   ‚îú‚îÄ‚îÄ IDENTITY.md                  # Externe Identit√§t
‚îÇ   ‚îú‚îÄ‚îÄ AGENTS.md                    # Verhaltensregeln
‚îÇ   ‚îú‚îÄ‚îÄ TOOLS.md                     # Tool-Nutzungsanleitung
‚îÇ   ‚îú‚îÄ‚îÄ HEARTBEAT.md                 # Proaktive Checkliste
‚îÇ   ‚îú‚îÄ‚îÄ BOOTSTRAP.md                 # Ersteinrichtung
‚îÇ   ‚îú‚îÄ‚îÄ MEMORY.md                    # Persistenter Speicher
‚îÇ   ‚îú‚îÄ‚îÄ memory/YYYY-MM-DD.md         # T√§gliche Logs
‚îÇ   ‚îî‚îÄ‚îÄ skills/                      # Workspace-Skills (h√∂chste Priorit√§t)
‚îú‚îÄ‚îÄ cron/                            # Cron-Job-Definitionen
‚îî‚îÄ‚îÄ tools/                           # Installierte Tool-Binaries
```

### Quellcode-Organisation

Das Repository (`github.com/openclaw/openclaw`) organisiert Code unter `src/` mit Schl√ºsselverzeichnissen:

| Verzeichnis | Inhalt |
|-------------|--------|
| `agents/` | System-Prompt, Skills, Tools, Model Auth, Sandbox, Session Management |
| `config/` | Zod-Schemas, Validierung, Hot Reload |
| `gateway/` | WebSocket-Server, Protokoll |
| `auto-reply/` | Command-System, Compaction |
| `infra/` | Heartbeat Runner |
| `memory/` | Manager, Indexierung |
| Kanal-spezifisch | Telegram, Discord, WhatsApp, etc. |

Das Projekt verwendet pnpm Workspaces mit TypeScript, Node 22+ Runtime und ko-lokalisierte `*.test.ts`-Dateien.

---

## 9. Framework-Empfehlung f√ºr den Nachbau

### √úbersicht der Optionen

| Framework | St√§rken | Schw√§chen | Eignung |
|-----------|---------|-----------|---------|
| **LangGraph** | Stateful Graphs, eingebautes Checkpointing (PostgresSaver/RedisSaver), LangSmith-Observability | Steile Lernkurve, kein natives Heartbeat/Scheduling | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Beste Balance |
| **Raw Python/TS** | Maximale Kontrolle, OpenClaw beweist Skalierbarkeit (185K+ Stars) | Maximaler Engineering-Aufwand, keine eingebaute Observability | ‚≠ê‚≠ê‚≠ê‚≠ê Wenn volle Kontrolle n√∂tig |
| **CrewAI** | Multi-Agent-Rollenspiel, einfaches Setup | Fehlende Feingranularit√§t f√ºr Single-Agent-mit-Subagenten | ‚≠ê‚≠ê‚≠ê F√ºr Multi-Agent-Szenarien |
| **LangChain Base** | Reichstes Integrations-√ñkosystem | √úberengineert einfache Tasks durch Abstraktionsebenen | ‚≠ê‚≠ê Zu viel Overhead |

### Empfehlung: LangGraph

**LangGraph bietet die beste Framework-Balance** f√ºr die meisten Teams:

- Stateful Directed Graphs passen nat√ºrlich auf Agentic Loops (jede Phase als Graph-Knoten mit bedingten Kanten)
- Eingebautes Checkpointing bietet die st√§rkste persistente Memory-Story
- LangSmith-Integration f√ºr Produktions-Observability
- Fehlt: natives Heartbeat/Scheduling (ben√∂tigt externen APScheduler) und Multi-Channel-Messaging (ben√∂tigt Custom Gateway Layer)

### Context-Window-Optimierung ‚Äî Die sieben Kerntechniken

Anthropics offizielle Guidance betont, dass **Modellgenauigkeit mit steigender Token-Anzahl abnimmt** ‚Äî jeder Token verbraucht das Aufmerksamkeitsbudget des Modells:

1. **Compaction** ‚Äî OpenClaws Ansatz: √Ñltere Historie zusammenfassen
2. **Strukturierte Notizenf√ºhrung au√üerhalb des Kontexts** ‚Äî Wissen in Dateien auslagern
3. **Sub-Agent-Architektur** mit frischem, minimalem Kontext
4. **Just-in-Time Context Retrieval** ‚Äî Daten via Tools laden statt vorab
5. **Selektive Kontext-Injektion** pro Agent-Rolle
6. **Prompt-Kompression** ‚Äî Redundante Formatierung und alte Tool-Ergebnisse entfernen
7. **Konservative Trigger bei 50% Context Usage** statt am Limit

**Der Trend geht zu Context Engineering** ‚Äî das Context Window als knappe Ressource behandeln, die aktiv gemanagt wird, nicht einfach gef√ºllt.

---

## 10. Schl√ºsselerkenntnisse f√ºr unseren Nachbau

### Die f√ºnf harten Probleme, die gleichzeitig gel√∂st werden m√ºssen

1. **Prompt-Assembly aus modularen Komponenten** (nicht monolithische Templates)
2. **Persistenter Memory mit Hybrid-Retrieval** der graceful degraded
3. **Aggressives Context-Window-Management** das archiviert bevor es vergisst
4. **Proaktives Verhalten** das im Auftrag des Nutzers handelt ohne Benachrichtigungs-Spam
5. **Skill-System** das F√§higkeiten entdeckt ohne Context-Budget zu verbrauchen

### Die √ºberraschendste Erkenntnis

**OpenClaw hat keinen expliziten Planer.** Das Sprachmodell selbst treibt den Think-Plan-Act-Observe-Loop durch iterative Tool-Aufrufe. Die Intelligenz steckt in der Prompt-Konstruktion, nicht in einem separaten Reasoning-Engine.

### Die folgenreichste Design-Entscheidung

**File-first Architektur:** Markdown-Dateien auf der Festplatte sind die Wahrheitsquelle f√ºr Pers√∂nlichkeit, Memory und Konfiguration, mit abgeleiteten Indizes f√ºr Suche. Das macht das System inspizierbar, versionskontrollierbar und wiederherstellbar ‚Äî aber es bedeutet auch, dass der System-Prompt mit jeder Datei w√§chst, was die **Spannung zwischen Reichhaltigkeit und Effizienz** erzeugt, die OpenClaws laufende Engineering-Herausforderung definiert.

### Was wir f√ºr Agent One √ºbernehmen

| OpenClaw-Konzept | Unsere Anpassung |
|------------------|-----------------|
| SOUL.md / IDENTITY.md | Pers√∂nlichkeitsdateien mit klarer Trennung intern/extern |
| MEMORY.md + Daily Logs | Persistenter Speicher in NocoDB/Supabase statt Dateien |
| Heartbeat System | APScheduler + LangGraph-Trigger statt Gateway-integriert |
| On-Demand Skill Loading | Skills als LangGraph-Sub-Workflows statt Markdown |
| Hybrid Search | Vektorsuche + Keyword-Suche in PostgreSQL (pgvector + tsvector) |
| Compaction | Strukturierte Zusammenfassung + Pre-Compaction Flush |
| Context Window Guard | Harte Token-Limits mit automatischer Warnung |
| Webhook-Anbindung | REST-API-Endpunkte f√ºr n8n/externe Systeme |

### N√§chste Schritte

1. **Tech-Stack finalisieren**: Next.js Frontend + Python/LangGraph Backend + PostgreSQL (pgvector)
2. **Pers√∂nlichkeitssystem implementieren**: Soul/Identity/User/Memory als DB-Eintr√§ge statt Dateien
3. **Agentic Loop mit LangGraph bauen**: Stateful Graph mit Tool-Nodes
4. **Heartbeat-System**: APScheduler mit konfigurierbaren Intervallen
5. **Webhook-Layer**: REST-Endpunkte f√ºr n8n-Anbindung
6. **Expo-App Integration**: WebSocket/SSE-Verbindung zum Backend

---

*Quellen: OpenClaw GitHub Repository, DeepWiki-Analyse, OpenClaw Official Docs, MMNTM Architecture Series, Anthropic Context Engineering Guide, diverse Community-Analysen (Medium, Substack, saulius.io)*
